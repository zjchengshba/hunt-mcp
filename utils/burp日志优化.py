import json
import re
from datetime import datetime
from config import BURP_LOG_PATH

# ===================== å·¥å…·é…ç½®ï¼ˆå¯æ ¹æ®éœ€æ±‚ä¿®æ”¹ï¼‰=====================
# 1. åŸå§‹ Burp æ—¥å¿—è·¯å¾„ï¼ˆè¾“å…¥æ–‡ä»¶ï¼‰
RAW_BURP_LOG_PATH = BURP_LOG_PATH  # åŸå§‹æ—¥å¿—æ–‡ä»¶ï¼ˆBurp è‡ªåŠ¨ä¿å­˜çš„æ—¥å¿—ï¼‰
# 2. ç­›é€‰åæ—¥å¿—å¯¼å‡ºè·¯å¾„ï¼ˆè¾“å‡ºæ–‡ä»¶ï¼Œè‡ªåŠ¨å¸¦æ—¶é—´æˆ³ï¼Œé¿å…è¦†ç›–ï¼‰
EXPORT_DIR = "./"
# 3. ç­›é€‰é…ç½®ï¼ˆå¯å¾®è°ƒï¼‰
MIN_JSON_LENGTH = 5  # æœ€å° JSON ç‰‡æ®µé•¿åº¦ï¼Œè¿‡æ»¤æ— æ„ä¹‰çš„çŸ­ç‰‡æ®µï¼ˆå¦‚ {}ã€{"k":""}ï¼‰
PRESERVE_TRAFFIC_CONTEXT = True  # ä¿æŒä¸º Trueï¼Œç¡®ä¿å®Œæ•´ä¿ç•™è¯·æ±‚å¤´+å“åº”å¤´+JSON è¿”å›ä½“
# 4. æ ¸å¿ƒç™½åå•ï¼šä»…ä¿ç•™è¯¥ Content-Type çš„æµé‡
WHITELIST_CONTENT_TYPE = "Content-Type: application/json"
# 5. æ–°å¢ï¼šURL åŒ¹é…å‚æ•°ï¼ˆä»…ä¿ç•™åŒ…å«è¯¥ URL å…³é”®å­—çš„æµé‡ï¼Œæ”¯æŒå®Œæ•´ URL æˆ–è·¯å¾„ç‰‡æ®µï¼Œå¤§å°å†™ä¸æ•æ„Ÿï¼‰
# ç¤ºä¾‹1ï¼šå®Œæ•´ URL â†’ "https://dipp.sf-express.com/api"
# ç¤ºä¾‹2ï¼šè·¯å¾„ç‰‡æ®µ â†’ "/api"ã€"/user/info"
TARGET_URL_KEYWORD = "eva2.csdn.net"  # å¯æ ¹æ®éœ€æ±‚ä¿®æ”¹ä¸ºä½ çš„ç›®æ ‡ URL/è·¯å¾„


# ===================== æ ¸å¿ƒè¿‡æ»¤é€»è¾‘ï¼ˆç™½åå•æ¨¡å¼ + URL åŒ¹é… + å®Œæ•´ä¿ç•™è¯·æ±‚å¤´ï¼‰=====================
def filter_burp_log_for_json(raw_log_content):
    """
    æ ¸å¿ƒå‡½æ•°ï¼šç­›é€‰åŸå§‹ Burp æ—¥å¿—ä¸­ å«ç›®æ ‡ URL + ç™½åå• Content-Type + æœ‰æ•ˆ JSON è¿”å›ä½“ çš„æµé‡æ¡ç›®
    å…³é”®ï¼š1. ä»…ä¿ç•™åŒ…å«ç›®æ ‡ URL çš„æµé‡ 2. å®Œæ•´ä¿ç•™è¯·æ±‚å¤´ã€å“åº”å¤´åŠ JSON è¿”å›ä½“
    :param raw_log_content: åŸå§‹ Burp æ—¥å¿—å†…å®¹
    :return: ç­›é€‰åçš„çº¯å‡€æ—¥å¿—å†…å®¹
    """
    # Burp æ—¥å¿—é»˜è®¤åˆ†éš”ç¬¦ï¼ˆç”¨äºæ‹†åˆ†å•ä¸ªæµé‡æ¡ç›®ï¼‰
    traffic_separator = "======================================================"
    # æ‹†åˆ†æ‰€æœ‰æµé‡æ¡ç›®
    traffic_entries = raw_log_content.split(traffic_separator)
    # å­˜å‚¨ç­›é€‰åçš„æœ‰æ•ˆæ¡ç›®
    valid_entries = []

    # æ­£åˆ™åŒ¹é…å®Œæ•´ JSON å—ï¼ˆæ”¯æŒè·¨è¡Œã€å«ç©ºæ ¼ï¼‰
    json_block_pattern = r'\{[\s\S]*?\}'
    # è¡¥å……åŒ¹é…æ•°ç»„æ ¼å¼ JSONï¼ˆå¯é€‰ï¼Œè‹¥æœ‰ [] æ ¼å¼çš„è¿”å›ä½“ï¼‰
    json_array_pattern = r'\[[\s\S]*?\]'

    print(f"ğŸ” å¼€å§‹è§£ææ—¥å¿—ï¼Œå…±æ£€æµ‹åˆ° {len(traffic_entries)} æ¡åŸå§‹æµé‡æ¡ç›®...")
    print(f"ğŸ“‹ ç™½åå•è§„åˆ™ï¼šä»…ä¿ç•™ {WHITELIST_CONTENT_TYPE} ç±»å‹æµé‡")
    print(f"ğŸ”— URL åŒ¹é…è§„åˆ™ï¼šä»…ä¿ç•™åŒ…å« '{TARGET_URL_KEYWORD}' çš„æµé‡ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰")
    print(f"ğŸ“Œ é…ç½®è¯´æ˜ï¼šå®Œæ•´ä¿ç•™è¯·æ±‚å¤´ã€å“åº”å¤´åŠ JSON è¿”å›ä½“")

    for entry in traffic_entries:
        # å…³é”®ï¼šä¸æå‰ strip æ•´ä¸ª entryï¼Œä»…ç”¨äºåˆ¤æ–­ç©ºæ¡ç›®ï¼ˆé¿å…ä¸¢å¤±è¯·æ±‚å¤´çš„æ ¼å¼å’Œç©ºæ ¼ï¼‰
        entry_original = entry  # ä¿ç•™åŸå§‹æ¡ç›®ï¼ˆå«æ ¼å¼ã€ç©ºæ ¼ï¼‰ï¼Œç¡®ä¿è¯·æ±‚å¤´å®Œæ•´
        entry_stripped = entry_original

        # è·³è¿‡ç©ºæ¡ç›®
        if not entry_stripped:
            continue

        # æ­¥éª¤ 1ï¼šæ–°å¢ URL åŒ¹é…ç­›é€‰â€”â€”ä»…ä¿ç•™åŒ…å«ç›®æ ‡ URL å…³é”®å­—çš„æµé‡ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿå…¼å®¹ï¼‰
        if TARGET_URL_KEYWORD.lower() not in entry_original.lower():
            continue

        # æ­¥éª¤ 2ï¼šæ ¸å¿ƒç™½åå•ç­›é€‰â€”â€”ä»…ä¿ç•™åŒ…å«æŒ‡å®š Content-Type çš„æµé‡ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿå…¼å®¹ï¼‰
        if WHITELIST_CONTENT_TYPE.lower() not in entry_original.lower():
            continue

        # æ­¥éª¤ 3ï¼šåˆæ­¥è¿‡æ»¤â€”â€”åˆ¤æ–­æ˜¯å¦åŒ…å« JSON ç‰¹å¾å­—ç¬¦
        if '{"' not in entry_original and '}' not in entry_original and '[' not in entry_original and ']' not in entry_original:
            continue

        # æ­¥éª¤ 4ï¼šæå–æ‰€æœ‰å¯èƒ½çš„ JSON å€™é€‰ç‰‡æ®µ
        json_candidates = re.findall(json_block_pattern, entry_original, re.DOTALL)
        json_candidates += re.findall(json_array_pattern, entry_original, re.DOTALL)
        valid_json_found = False

        # æ­¥éª¤ 5ï¼šéªŒè¯å€™é€‰ç‰‡æ®µæ˜¯å¦ä¸ºåˆæ³• JSON
        for candidate in json_candidates:
            candidate_stripped = candidate.strip()
            # è¿‡æ»¤è¿‡çŸ­çš„æ— æ•ˆç‰‡æ®µ
            if len(candidate_stripped) < MIN_JSON_LENGTH:
                continue

            # å°è¯•è§£æ JSONï¼ˆå¤„ç†å¸¸è§æ ¼å¼é—®é¢˜ï¼šæœ«å°¾å¤šä½™é€—å·ã€åˆ†å·ã€æ‹¬å·ï¼‰
            try:
                # ç®€å•ä¿®å¤ä¸è§„èŒƒ JSON
                fixed_candidate = candidate_stripped.rstrip(',').rstrip(';').rstrip(')').rstrip('}')
                # è¡¥å…¨ç¼ºå¤±çš„é—­åˆç¬¦ï¼ˆç®€å•åœºæ™¯ï¼‰
                if fixed_candidate.count('{') > fixed_candidate.count('}'):
                    fixed_candidate += '}' * (fixed_candidate.count('{') - fixed_candidate.count('}'))
                if fixed_candidate.count('[') > fixed_candidate.count(']'):
                    fixed_candidate += ']' * (fixed_candidate.count('[') - fixed_candidate.count(']'))

                # éªŒè¯åˆæ³•æ€§
                json.loads(fixed_candidate)
                valid_json_found = True
                break
            except json.JSONDecodeError:
                continue

        # æ­¥éª¤ 6ï¼šä¿ç•™æœ‰æ•ˆæ¡ç›®ï¼ˆå®Œæ•´ä¿ç•™è¯·æ±‚å¤´+å“åº”å¤´+JSONï¼Œä¸ä¿®æ”¹åŸå§‹æ ¼å¼ï¼‰
        if valid_json_found:
            if PRESERVE_TRAFFIC_CONTEXT:
                # å…³é”®ï¼šæ·»åŠ åŸå§‹æ¡ç›®ï¼ˆentry_originalï¼‰ï¼Œè€Œé stripped åçš„æ¡ç›®ï¼Œç¡®ä¿è¯·æ±‚å¤´å®Œæ•´æ— ä¸¢å¤±
                valid_entries.append(entry_original)
            else:
                # ä»…ä¿ç•™çº¯ JSON å†…å®¹ï¼ˆå¦‚éœ€æ­¤æ¨¡å¼ï¼Œå¯å°† PRESERVE_TRAFFIC_CONTEXT æ”¹ä¸º Falseï¼‰
                pure_json = "\n".join([c for c in json_candidates if len(c.strip()) >= MIN_JSON_LENGTH])
                valid_entries.append(pure_json)

    # æ­¥éª¤ 7ï¼šé‡ç»„ç­›é€‰åçš„æ—¥å¿—ï¼ˆè¿˜åŸåˆ†éš”ç¬¦ï¼Œä¿æŒæ ¼å¼æ¸…æ™°ï¼Œè¯·æ±‚å¤´å®Œæ•´ï¼‰
    filtered_log = traffic_separator.join(valid_entries)
    print(f"âœ… æ—¥å¿—ç­›é€‰å®Œæˆï¼Œå…±ä¿ç•™ {len(valid_entries)} æ¡ç¬¦åˆ URL åŒ¹é…+ç™½åå•çš„æœ‰æ•ˆ JSON æµé‡æ¡ç›®")
    return filtered_log


# ===================== æ–‡ä»¶è¯»å†™ä¸å¯¼å‡ºï¼ˆæ— éœ€ä¿®æ”¹ï¼‰=====================
def run_json_log_filter():
    """è¿è¡Œå®Œæ•´çš„æ—¥å¿—è¿‡æ»¤æµç¨‹ï¼šè¯»å– â†’ ç­›é€‰ â†’ å¯¼å‡º"""
    try:
        # 1. è¯»å–åŸå§‹ Burp æ—¥å¿—æ–‡ä»¶
        print(f"ğŸ“‚ æ­£åœ¨è¯»å–åŸå§‹æ—¥å¿—æ–‡ä»¶ï¼š{RAW_BURP_LOG_PATH}")
        with open(RAW_BURP_LOG_PATH, "r", encoding="utf-8", errors="ignore") as f:
            raw_log_content = f.read()

        if not raw_log_content.strip():
            print("âŒ åŸå§‹æ—¥å¿—æ–‡ä»¶ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œç­›é€‰")
            return

        # 2. æ‰§è¡Œ JSON æµé‡ç­›é€‰ï¼ˆURL åŒ¹é… + ç™½åå•æ¨¡å¼ + å®Œæ•´ä¿ç•™è¯·æ±‚å¤´ï¼‰
        filtered_log_content = filter_burp_log_for_json(raw_log_content)

        # 3. ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å¯¼å‡ºæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # æ–‡ä»¶åæ·»åŠ  url_match æ ‡è¯†ï¼Œæ–¹ä¾¿åŒºåˆ†
        export_filename = f"{EXPORT_DIR}burp_url_match_{TARGET_URL_KEYWORD.replace('/', '_').replace(':', '')}_application_json_{timestamp}.log"

        # 4. å¯¼å‡ºç­›é€‰åçš„æ—¥å¿—æ–‡ä»¶
        with open(export_filename, "w", encoding="utf-8") as f:
            f.write(filtered_log_content)

        print(f"ğŸ“¤ ç­›é€‰åçš„æ—¥å¿—å·²å¯¼å‡ºï¼š{export_filename}")
        print(f"ğŸ‰ æ•´ä¸ªè¿‡æ»¤æµç¨‹å®Œæˆï¼Œæ—¥å¿—å®Œæ•´ä¿ç•™è¯·æ±‚å¤´ã€å“åº”å¤´åŠ JSON è¿”å›ä½“")

    except FileNotFoundError:
        print(f"âŒ æœªæ‰¾åˆ°åŸå§‹æ—¥å¿—æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼š{RAW_BURP_LOG_PATH}")
    except Exception as e:
        print(f"âŒ è¿‡æ»¤æµç¨‹å‡ºç°å¼‚å¸¸ï¼š{str(e)}")


# ===================== è¿è¡Œå·¥å…·ï¼ˆç›´æ¥æ‰§è¡Œå³å¯ï¼‰=====================
if __name__ == "__main__":
    print("=" * 60)
    print("  Burp æ—¥å¿— JSON æå–å·¥å…·ï¼ˆURL åŒ¹é… + ç™½åå•ç‰ˆ + å®Œæ•´ä¿ç•™è¯·æ±‚å¤´ï¼‰")
    print("=" * 60)
    run_json_log_filter()